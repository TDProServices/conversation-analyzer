# Conversation Analyzer Configuration

ollama:
  host: "http://localhost:11434"
  extraction_model: "nuextract"
  analysis_model: "llama3.1:8b"
  temperature: 0.1
  max_tokens: 2048
  timeout: 60

extraction:
  prompt_version: "v1.0"
  confidence_threshold: 0.5
  batch_size: 10
  chunk_size: 1800  # tokens, leave room for prompt

intelligence:
  deduplication:
    enabled: true
    similarity_threshold: 0.85
    embedding_model: "all-MiniLM-L6-v2"

  priority_scoring:
    urgency_keywords: ["urgent", "critical", "asap", "immediately", "blocker"]
    impact_keywords: ["breaks", "blocks", "prevents", "security", "data loss"]
    base_score: 0.5

  entity_linking:
    enabled: true
    min_entities_shared: 1

database:
  path: "data/database/analyzer.db"
  backup_enabled: true
  backup_interval: 86400  # seconds (1 day)

reporting:
  output_dir: "data/reports"
  formats: ["markdown", "json"]
  group_by: "type"  # type, priority, source
  include_duplicates: false

logging:
  level: "INFO"
  file: "data/logs/analyzer.log"
  console: true

sources:
  conversations:
    - "data/conversations/**/*.md"
    - "data/conversations/**/*.json"
  code:
    - "**/*.py"
    - "**/*.js"
    - "**/*.ts"
  documents:
    - "**/TODO.md"
    - "**/README.md"
    - "**/NOTES.md"
  git:
    enabled: false
    branch: "main"
    since: "30 days ago"
