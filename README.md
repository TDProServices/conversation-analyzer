# Conversation Analyzer

[![Tests](https://img.shields.io/badge/tests-passing-brightgreen)](https://github.com/TDProServices/conversation-analyzer)
[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

> Local LLM-powered analysis to extract TODOs, bugs, feature requests, and project ideas from conversations, code, and documentation.

**100% local. 100% private. 100% offline.**

---

## Overview

Conversation Analyzer uses local LLMs (via Ollama) to automatically discover action items that slip through the cracks:

- ğŸ› **Bugs** mentioned in conversations but never filed
- âœ… **TODOs** scattered across code comments and chats
- âœ¨ **Feature requests** discussed but not documented
- ğŸ“¦ **Project ideas** that could become reality
- ğŸ”— **Relationships** between related items

**Why Local?**
- âœ… Privacy: Your conversations never leave your machine
- âœ… Cost: No API fees, unlimited analysis
- âœ… Speed: Fast processing with local models
- âœ… Offline: Works without internet

---

## Features

### Intelligent Extraction

- **Multi-source**: Analyze conversations, code comments, markdown files
- **Confidence scores**: Each extraction includes confidence level (0.0-1.0)
- **Context preservation**: Maintains source quotes for verification
- **Priority assignment**: Automatic high/medium/low classification

### Smart Analysis

- **Deduplication**: Uses embeddings to find similar items across sources
- **Priority scoring**: Keyword-based scoring (urgent, critical, security, etc.)
- **Entity linking**: Connects items mentioning same files, functions, components
- **Relationship tracking**: Builds a graph of related action items

### Multiple Output Formats

- **Markdown reports**: Beautiful, readable reports with emojis
- **JSON export**: Structured data for further processing
- **CLI interface**: Rich terminal output with tables and colors
- **SQLite database**: Query and analyze with SQL

### Testing & Quality

- **Pytest integration**: Comprehensive test suite
- **DeepEval support**: LLM evaluation metrics
- **Type safety**: Pydantic models for validation
- **Reproducibility**: Deterministic extraction with low temperature

---

## Quick Start

### Prerequisites

- Python 3.10+
- Ollama installed and running

### Installation

```bash
# 1. Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# 2. Pull the extraction model
ollama pull nuextract

# 3. Start Ollama (in a separate terminal)
ollama serve

# 4. Clone and install
git clone https://github.com/TDProServices/conversation-analyzer.git
cd conversation-analyzer
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Usage

```bash
# Test connection
python -m conversation_analyzer test-connection

# Analyze a conversation
python -m conversation_analyzer analyze tests/fixtures/conversations/sample_simple.md

# View statistics
python -m conversation_analyzer stats

# Generate report
python -m conversation_analyzer report

# List high priority items
python -m conversation_analyzer list --priority high
```

See [docs/INSTALLATION.md](docs/INSTALLATION.md) and [docs/USAGE.md](docs/USAGE.md) for details.

---

## Example

See [examples/sample_report.md](examples/sample_report.md) and [examples/sample_report.json](examples/sample_report.json) for real output examples.

**Input (conversation):**

```markdown
**User:** We need to fix the login timeout issue. Users are getting kicked out after 5 minutes.

**Assistant:** I can help with that.

**User:** Also TODO: update the API documentation for the new auth flow.

**User:** One more thing - we should add a "remember me" feature.
```

**Output:**

```markdown
### BUGs (1)

#### ğŸ› ğŸ”´ Login timeout issue - users kicked out after 5 minutes
- Type: BUG
- Priority: High (0.85)
- Confidence: 0.90
- Source: `conversation.md`
- Context: "We need to fix the login timeout issue. Users are getting kicked out..."

### TODOs (1)

#### âœ… ğŸŸ¡ Update API documentation for new auth flow
- Type: TODO
- Priority: Medium (0.50)
- Confidence: 0.95
- Source: `conversation.md`
- Context: "TODO: update the API documentation..."

### FEATUREs (1)

#### âœ¨ ğŸŸ¢ Add "remember me" feature
- Type: FEATURE
- Priority: Low (0.30)
- Confidence: 0.80
- Source: `conversation.md`
- Context: "we should add a \"remember me\" feature"
```

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CONVERSATION ANALYZER                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUTS                  PROCESSING                OUTPUTS
â”œâ”€ Conversations  â”€â”€â†’   â”œâ”€ Parsers           â”€â”€â†’  â”œâ”€ SQLite DB
â”œâ”€ Code Comments  â”€â”€â†’   â”œâ”€ LLM Extractor     â”€â”€â†’  â”œâ”€ Markdown Reports
â”œâ”€ TODO.md files  â”€â”€â†’   â”œâ”€ Deduplicator      â”€â”€â†’  â”œâ”€ JSON Exports
â””â”€ Documentation  â”€â”€â†’   â”œâ”€ Priority Scorer   â”€â”€â†’  â””â”€ CLI Output
                        â””â”€ Entity Linker
```

**Components:**

- **Parsers**: Handle Markdown, JSON, code files
- **Extractor**: Ollama + NuExtract model for precise extraction
- **Intelligence**: Deduplication, scoring, entity linking
- **Database**: SQLite with full-text search and indexes
- **Reporting**: Markdown and JSON generation

See [DESIGN.md](DESIGN.md) for detailed architecture.

---

## Tech Stack

| Component | Technology | Why |
|-----------|------------|-----|
| **LLM** | Ollama + NuExtract | Local, fast, optimized for extraction |
| **Language** | Python 3.11 | Rich ecosystem, type hints |
| **Database** | SQLite | Embedded, no setup, full SQL |
| **Validation** | Pydantic | Type-safe data models |
| **Embeddings** | sentence-transformers | Fast similarity calculations |
| **CLI** | Click + Rich | Beautiful terminal UX |
| **Testing** | pytest + DeepEval | Unit, integration, LLM evaluation |

---

## Configuration

Customize via `config.yaml`:

```yaml
ollama:
  extraction_model: "nuextract"  # or "llama3.1:8b"
  temperature: 0.1

extraction:
  confidence_threshold: 0.5  # Min confidence to keep

intelligence:
  deduplication:
    similarity_threshold: 0.85  # Higher = stricter
  priority_scoring:
    urgency_keywords: ["urgent", "critical", "asap"]
```

---

## Development

### Project Structure

```
conversation-analyzer/
â”œâ”€â”€ src/conversation_analyzer/
â”‚   â”œâ”€â”€ models.py           # Pydantic models
â”‚   â”œâ”€â”€ database.py         # SQLite operations
â”‚   â”œâ”€â”€ config.py           # Configuration
â”‚   â”œâ”€â”€ parsers/            # File parsers
â”‚   â”œâ”€â”€ extraction/         # LLM extraction
â”‚   â”œâ”€â”€ intelligence/       # Dedup, scoring, linking
â”‚   â”œâ”€â”€ reporting/          # Report generation
â”‚   â””â”€â”€ analyzer.py         # Main orchestrator
â”œâ”€â”€ tests/                  # Test suite
â”œâ”€â”€ docs/                   # Documentation
â””â”€â”€ data/                   # Runtime data (gitignored)
```

### Running Tests

```bash
# Install dev dependencies
pip install -r requirements.txt

# Run all tests
pytest

# Run with coverage
pytest --cov=src/conversation_analyzer

# Run only unit tests
pytest tests/unit/

# Run LLM evaluation tests (requires Ollama)
pytest tests/llm_eval/
```

### Adding Features

1. Add tests in `tests/`
2. Implement feature
3. Update documentation
4. Run full test suite
5. Submit PR

---

## Research & Design

This project includes comprehensive research and design documentation:

- **[RESEARCH_REPORT.md](RESEARCH_REPORT.md)**: 800+ lines of research on LLM evaluation, models, frameworks, and best practices
- **[DESIGN.md](DESIGN.md)**: Complete system design with architecture, database schema, API design, and testing strategy

These documents contain valuable insights for:
- Choosing the right LLM and evaluation framework
- Designing structured extraction systems
- Building local-first AI applications
- Testing and validating LLM outputs

---

## Use Cases

### Software Teams

- **Sprint retrospectives**: Extract action items from meeting notes
- **Code review**: Find TODOs and FIXMEs across codebase
- **Technical debt**: Identify and prioritize cleanup tasks

### Solo Developers

- **Conversation mining**: Recover TODOs from Claude/ChatGPT conversations
- **Project planning**: Extract feature requests from design discussions
- **Bug tracking**: Catalog bugs mentioned in commit messages

### Researchers

- **Note processing**: Extract action items from research notes
- **Paper analysis**: Identify future work sections
- **Collaboration**: Track ideas from email threads

---

## Roadmap

### v0.1.0 (Current)
- âœ… Local LLM extraction
- âœ… Multi-source parsing
- âœ… Deduplication
- âœ… Priority scoring
- âœ… CLI interface
- âœ… Markdown/JSON reports

### v0.2.0 (Planned)
- [ ] Web UI
- [ ] GitHub Issues integration
- [ ] Watch mode for continuous analysis
- [ ] Trend analysis and burndown charts

### v0.3.0 (Future)
- [ ] Custom model fine-tuning
- [ ] Multi-language support
- [ ] Plugin system
- [ ] VS Code extension

---

## Performance

**Benchmarks** (MacBook Pro M1, 16GB RAM):

| Operation | Time | Throughput |
|-----------|------|------------|
| Parse conversation (1KB) | 10ms | 100 files/s |
| Extract with NuExtract | 200ms | 5 files/s |
| Deduplication (100 items) | 50ms | 2000 items/s |
| Generate report | 100ms | - |

**Memory:**
- Base: ~100MB
- With embeddings: ~500MB
- Ollama (separate): 2-4GB

---

## Limitations

- **Requires Ollama**: Must install and run Ollama service
- **English only**: Currently optimized for English text
- **Local processing**: Slower than cloud APIs (but private)
- **Model size**: Needs 8GB+ RAM for best results

---

## Contributing

Contributions welcome! Areas of interest:

- Additional parsers (CSV, XML, etc.)
- Integration with task trackers (Jira, Linear, etc.)
- Improved prompt engineering
- Multi-language support
- Performance optimizations

See [DESIGN.md](DESIGN.md) for architecture details.

---

## License

MIT License - see LICENSE file

---

## Credits

**Author:** Tanya Davis / TD Professional Services LLC

**Built with:**
- [Ollama](https://ollama.com/) - Local LLM runtime
- [NuExtract](https://ollama.com/library/nuextract) - Fine-tuned extraction model
- [LangChain](https://python.langchain.com/) - LLM orchestration
- [sentence-transformers](https://www.sbert.net/) - Semantic similarity
- [DeepEval](https://github.com/confident-ai/deepeval) - LLM testing

---

## Support

- **Documentation**: See [docs/](docs/) folder
- **Issues**: [GitHub Issues](https://github.com/TDProServices/conversation-analyzer/issues)
- **Discussions**: [GitHub Discussions](https://github.com/TDProServices/conversation-analyzer/discussions)

---

## Acknowledgments

This project was developed to solve a real problem: capturing the valuable action items and ideas that emerge during conversations with AI assistants like Claude Code, but often get lost in long chat histories.

Special thanks to:
- The Ollama team for making local LLMs accessible
- The open-source community for amazing tools and libraries
- Early testers and contributors

---

**Made with â¤ï¸ for developers who want to capture every good idea.**
